{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "760608fd-8622-46cb-aecd-64fdfc37f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for cls in os.listdir(DATA_DIR):\n",
    "    cls_path =_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f54f35f5-a821-4a4d-ae1a-e789435dea07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dataset folder structure and image counts...\n",
      "Class 'A': 3 images\n",
      "Class 'B': 3 images\n",
      "Class 'C': 3 images\n",
      "Class 'D': 3 images\n",
      "Class 'E': 3 images\n",
      "Class 'F': 3 images\n",
      "Class 'G': 3 images\n",
      "Class 'H': 3 images\n",
      "Class 'I': 3 images\n",
      "Class 'J': 3 images\n",
      "Class 'K': 3 images\n",
      "Class 'L': 3 images\n",
      "Class 'M': 3 images\n",
      "Class 'N': 3 images\n",
      "Class 'O': 3 images\n",
      "Class 'P': 3 images\n",
      "Class 'Q': 3 images\n",
      "Class 'R': 3 images\n",
      "Class 'S': 3 images\n",
      "Class 'T': 3 images\n",
      "Class 'U': 3 images\n",
      "Class 'V': 3 images\n",
      "Class 'W': 3 images\n",
      "Class 'X': 3 images\n",
      "Class 'Y': 3 images\n",
      "Class 'Z': 3 images\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# Dataset check\n",
    "# =======================\n",
    "\n",
    "print(\"Checking dataset folder structure and image counts...\")\n",
    "\n",
    "total_images = 0\n",
    "empty_classes = []\n",
    "\n",
    "for cls in os.listdir(DATA_DIR):\n",
    "    cls_path = os.path.join(DATA_DIR, cls)\n",
    "    if os.path.isdir(cls_path):\n",
    "        num_imgs = len([f for f in os.listdir(cls_path) \n",
    "                        if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff', '.gif'))])\n",
    "        print(f\"Class '{cls}': {num_imgs} images\")\n",
    "        total_images += num_imgs\n",
    "        if num_imgs == 0:\n",
    "            empty_classes.append(cls)\n",
    "\n",
    "if total_images == 0:\n",
    "    raise ValueError(f\"No images found in '{DATA_DIR}'. Check your dataset path and folder structure!\")\n",
    "\n",
    "if empty_classes:\n",
    "    print(f\"Warning: The following classes are empty: {empty_classes}\")\n",
    "    print(\"These classes will be ignored by the generator.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e857bc5f-7d64-4387-a907-90d4611207fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dataset folder structure and image counts...\n",
      "Class 'A': 3 images\n",
      "Class 'B': 3 images\n",
      "Class 'C': 3 images\n",
      "Class 'D': 3 images\n",
      "Class 'E': 3 images\n",
      "Class 'F': 3 images\n",
      "Class 'G': 3 images\n",
      "Class 'H': 3 images\n",
      "Class 'I': 3 images\n",
      "Class 'J': 3 images\n",
      "Class 'K': 3 images\n",
      "Class 'L': 3 images\n",
      "Class 'M': 3 images\n",
      "Class 'N': 3 images\n",
      "Class 'O': 3 images\n",
      "Class 'P': 3 images\n",
      "Class 'Q': 3 images\n",
      "Class 'R': 3 images\n",
      "Class 'S': 3 images\n",
      "Class 'T': 3 images\n",
      "Class 'U': 3 images\n",
      "Class 'V': 3 images\n",
      "Class 'W': 3 images\n",
      "Class 'X': 3 images\n",
      "Class 'Y': 3 images\n",
      "Class 'Z': 3 images\n",
      "Found 78 images belonging to 26 classes.\n",
      "Found 78 images belonging to 26 classes.\n",
      "Class weights: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0, 20: 1.0, 21: 1.0, 22: 1.0, 23: 1.0, 24: 1.0, 25: 1.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"compact_sasl_cnn\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"compact_sasl_cnn\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_21               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_22               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_23               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,354</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_21               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_21 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_22               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_22 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_23               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_23 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)                  │           \u001b[38;5;34m3,354\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,010</span> (445.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m114,010\u001b[0m (445.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">113,562</span> (443.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m113,562\u001b[0m (443.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seithati\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.0000e+00 - loss: 3.5185\n",
      "Epoch 1: val_accuracy improved from -inf to 0.03846, saving model to models\\sasl_cnn.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 726ms/step - accuracy: 0.0000e+00 - loss: 3.5199 - val_accuracy: 0.0385 - val_loss: 3.2714 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - accuracy: 0.0161 - loss: 3.3008\n",
      "Epoch 2: val_accuracy improved from 0.03846 to 0.05128, saving model to models\\sasl_cnn.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 629ms/step - accuracy: 0.0156 - loss: 3.3133 - val_accuracy: 0.0513 - val_loss: 3.2713 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - accuracy: 0.0949 - loss: 3.4539\n",
      "Epoch 3: val_accuracy did not improve from 0.05128\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 624ms/step - accuracy: 0.0898 - loss: 3.4444 - val_accuracy: 0.0385 - val_loss: 3.2712 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.0116 - loss: 3.4220  \n",
      "Epoch 4: val_accuracy did not improve from 0.05128\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 589ms/step - accuracy: 0.0139 - loss: 3.4126 - val_accuracy: 0.0385 - val_loss: 3.2711 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - accuracy: 0.0603 - loss: 3.3531\n",
      "Epoch 5: val_accuracy did not improve from 0.05128\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 596ms/step - accuracy: 0.0588 - loss: 3.3572 - val_accuracy: 0.0385 - val_loss: 3.2713 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - accuracy: 0.0672 - loss: 3.4075\n",
      "Epoch 6: val_accuracy did not improve from 0.05128\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 620ms/step - accuracy: 0.0709 - loss: 3.3978 - val_accuracy: 0.0385 - val_loss: 3.2717 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - accuracy: 0.0168 - loss: 3.3365\n",
      "Epoch 7: val_accuracy did not improve from 0.05128\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 623ms/step - accuracy: 0.0161 - loss: 3.3407 - val_accuracy: 0.0385 - val_loss: 3.2721 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - accuracy: 0.0644 - loss: 3.4053\n",
      "Epoch 8: val_accuracy did not improve from 0.05128\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 619ms/step - accuracy: 0.0622 - loss: 3.4055 - val_accuracy: 0.0385 - val_loss: 3.2724 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - accuracy: 0.0639 - loss: 3.2728\n",
      "Epoch 9: val_accuracy did not improve from 0.05128\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 582ms/step - accuracy: 0.0639 - loss: 3.2705 - val_accuracy: 0.0385 - val_loss: 3.2729 - learning_rate: 5.0000e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - accuracy: 0.0151 - loss: 3.2506\n",
      "Epoch 10: val_accuracy did not improve from 0.05128\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 591ms/step - accuracy: 0.0190 - loss: 3.2487 - val_accuracy: 0.0385 - val_loss: 3.2736 - learning_rate: 5.0000e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - accuracy: 0.0673 - loss: 3.3083\n",
      "Epoch 11: val_accuracy did not improve from 0.05128\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 653ms/step - accuracy: 0.0646 - loss: 3.3065 - val_accuracy: 0.0385 - val_loss: 3.2744 - learning_rate: 5.0000e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - accuracy: 0.0252 - loss: 3.2903\n",
      "Epoch 12: val_accuracy did not improve from 0.05128\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 593ms/step - accuracy: 0.0274 - loss: 3.2925 - val_accuracy: 0.0385 - val_loss: 3.2752 - learning_rate: 5.0000e-05\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers, optimizers, callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "\n",
    "DATA_DIR = \"labelled\"          \n",
    "MODEL_DIR = \"models\"\n",
    "LOG_DIR = os.path.join(MODEL_DIR, \"logs\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "IMG_SIZE = (128, 128)        \n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20                  \n",
    "SEED = 42\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_CLASSES = 26             \n",
    "\n",
    "# =======================\n",
    "# Dataset check\n",
    "# =======================\n",
    "\n",
    "print(\"Checking dataset folder structure and image counts...\")\n",
    "\n",
    "total_images = 0\n",
    "empty_classes = []\n",
    "\n",
    "for cls in os.listdir(DATA_DIR):\n",
    "    cls_path = os.path.join(DATA_DIR, cls)\n",
    "    if os.path.isdir(cls_path):\n",
    "        num_imgs = len([f for f in os.listdir(cls_path) \n",
    "                        if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff', '.gif'))])\n",
    "        print(f\"Class '{cls}': {num_imgs} images\")\n",
    "        total_images += num_imgs\n",
    "        if num_imgs == 0:\n",
    "            empty_classes.append(cls)\n",
    "\n",
    "if total_images == 0:\n",
    "    raise ValueError(f\"No images found in '{DATA_DIR}'. Check your dataset path and folder structure!\")\n",
    "\n",
    "if empty_classes:\n",
    "    print(f\"Warning: The following classes are empty and will be ignored: {empty_classes}\")\n",
    "\n",
    "# =======================\n",
    "# Data generators with augmentation\n",
    "# =======================\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.10,\n",
    "    height_shift_range=0.10,\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.10,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.8, 1.2),\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Use same dataset as \"validation\" (or optionally hold out a few images manually)\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# Compute class weights\n",
    "# =======================\n",
    "\n",
    "y_train_labels = train_generator.classes  \n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train_labels),\n",
    "    y=y_train_labels\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# =======================\n",
    "# Model definition\n",
    "# =======================\n",
    "\n",
    "def build_compact_cnn(input_shape=IMG_SIZE + (3,), num_classes=NUM_CLASSES):\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    # Global pooling\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=outputs, name=\"compact_sasl_cnn\")\n",
    "    return model\n",
    "\n",
    "model = build_compact_cnn()\n",
    "model.summary()\n",
    "\n",
    "# =======================\n",
    "# Compile model\n",
    "# =======================\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# Callbacks\n",
    "# =======================\n",
    "\n",
    "checkpoint_path = os.path.join(MODEL_DIR, \"sasl_cnn.keras\")\n",
    "cb_checkpoint = callbacks.ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    mode=\"max\",\n",
    "    verbose=1\n",
    ")\n",
    "cb_earlystop = callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=8,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "cb_reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=4,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "tensorboard_cb = callbacks.TensorBoard(log_dir=LOG_DIR)\n",
    "\n",
    "# =======================\n",
    "# Train\n",
    "# =======================\n",
    "\n",
    "steps_per_epoch = math.ceil(train_generator.samples / BATCH_SIZE)\n",
    "validation_steps = math.ceil(validation_generator.samples / BATCH_SIZE)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[cb_checkpoint, cb_earlystop, cb_reduce_lr, tensorboard_cb],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# Save final model\n",
    "# =======================\n",
    "\n",
    "model.save(os.path.join(MODEL_DIR, \"finalX1_sasl_cnn.keras\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c0b25c2-b538-4704-b362-937d853ad820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.0310 - loss: 3.2742\n",
      "Validation accuracy: 0.0385, Validation loss: 3.2711\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001CE2DE47240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001CE2DE47240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00         3\n",
      "           B       0.00      0.00      0.00         3\n",
      "           C       0.00      0.00      0.00         3\n",
      "           D       0.00      0.00      0.00         3\n",
      "           E       0.00      0.00      0.00         3\n",
      "           F       0.00      0.00      0.00         3\n",
      "           G       0.00      0.00      0.00         3\n",
      "           H       0.00      0.00      0.00         3\n",
      "           I       0.00      0.00      0.00         3\n",
      "           J       0.00      0.00      0.00         3\n",
      "           K       0.00      0.00      0.00         3\n",
      "           L       0.00      0.00      0.00         3\n",
      "           M       0.00      0.00      0.00         3\n",
      "           N       0.04      1.00      0.08         3\n",
      "           O       0.00      0.00      0.00         3\n",
      "           P       0.00      0.00      0.00         3\n",
      "           Q       0.00      0.00      0.00         3\n",
      "           R       0.00      0.00      0.00         3\n",
      "           S       0.00      0.00      0.00         3\n",
      "           T       0.00      0.00      0.00         3\n",
      "           U       0.00      0.00      0.00         3\n",
      "           V       0.00      0.00      0.00         3\n",
      "           W       0.00      0.00      0.00         3\n",
      "           X       0.00      0.00      0.00         3\n",
      "           Y       0.00      0.00      0.00         3\n",
      "           Z       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.04        78\n",
      "   macro avg       0.00      0.04      0.00        78\n",
      "weighted avg       0.00      0.04      0.00        78\n",
      "\n",
      "Confusion matrix:\n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 2 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =======================\n",
    "# Evaluate on validation set\n",
    "# =======================\n",
    "\n",
    "val_loss, val_acc = model.evaluate(validation_generator, steps=validation_steps, verbose=1)\n",
    "print(f\"Validation accuracy: {val_acc:.4f}, Validation loss: {val_loss:.4f}\")\n",
    "\n",
    "# =======================\n",
    "# Classification report & confusion matrix\n",
    "# =======================\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "validation_generator.reset()\n",
    "for i in range(validation_steps):\n",
    "    x_batch, y_batch = next(validation_generator)\n",
    "    preds = model.predict(x_batch)\n",
    "    y_true.extend(np.argmax(y_batch, axis=1).tolist())\n",
    "    y_pred.extend(np.argmax(preds, axis=1).tolist())\n",
    "\n",
    "idx_to_class = {v:k for k,v in train_generator.class_indices.items()}\n",
    "\n",
    "cm = skm.confusion_matrix(y_true, y_pred)\n",
    "report = skm.classification_report(y_true, y_pred, target_names=[idx_to_class[i] for i in range(len(idx_to_class))], zero_division=0)\n",
    "print(\"Classification report:\\n\", report)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "np.save(os.path.join(MODEL_DIR, \"confusion_matrix.npy\"), cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed560645-11a8-4162-91ef-d2249a1aeb13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
